# -*- coding: utf-8 -*-
"""multiple_ml_algorithms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19b5w4CeJ2AO8uEaBZHPCpdCl724jrVEE

## Telecom Churn Case Study
With 21 predictor variables we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, this is referred to as churning and not churning, respectively.

### Step 1: Importing and Merging Data
"""

# Suppressing Warnings
import warnings
warnings.filterwarnings('ignore')

# Importing Pandas and NumPy
import pandas as pd, numpy as np
from sklearn.metrics import classification_report

# Importing all datasets
churn_data = pd.read_csv("/content/churn_data (1).csv")
churn_data.head()

customer_data = pd.read_csv("/content/customer_data (1).csv")
customer_data.head()

internet_data = pd.read_csv("/content/internet_data (1).csv")
internet_data.head()

# Merging on 'customerID'
df_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')

# Final dataframe with all predictor variables
telecom = pd.merge(df_1, internet_data, how='inner', on='customerID')

"""### Step 2: Inspecting the Dataframe"""

# Let's see the head of our master dataset
telecom.head()

# Let's check the dimensions of the dataframe
telecom.shape

# let's look at the statistical aspects of the dataframe
telecom.describe()

# Let's see the type of each column
telecom.info()

telecom['Churn'].value_counts()

"""### Step 3: Data Preparation

#### Converting some binary variables (Yes/No) to 0/1
"""

# List of variables to map

varlist =  ['PhoneService', 'PaperlessBilling', 'Churn', 'Partner', 'Dependents']

# Defining the map function
def binary_map(x):
    return x.map({'Yes': 1, "No": 0})

# Applying the function to the housing list
telecom[varlist] = telecom[varlist].apply(binary_map)

telecom.head()

# Creating dummy variables for the remaining categorical variables and dropping the level with big names.

# # Creating dummy variables for the remaining categorical variables and dropping the level with big names.

def binary_dummies(x):
    return x.map({True: 1, False : 0})

telecom['gender'].replace([0,1],['Female','Male'],inplace=True)


# Creating dummy variables for the variable 'MultipleLines'
ml = pd.get_dummies(telecom['MultipleLines'], prefix='MultipleLines')
# Dropping MultipleLines_No phone service column
ml1 = ml.drop(['MultipleLines_No phone service'],axis =  1)
ml1 = ml1.apply(binary_dummies)
telecom = pd.concat([telecom,ml1], axis=1)

# Creating dummy variables for the variable 'OnlineSecurity'.
os = pd.get_dummies(telecom['OnlineSecurity'], prefix='OnlineSecurity')
os1 = os.drop(['OnlineSecurity_No internet service'], axis =  1)
os1 = os1.apply(binary_dummies)
telecom = pd.concat([telecom,os1], axis=1)

# Creating dummy variables for the variable 'OnlineBackup'.
ob = pd.get_dummies(telecom['OnlineBackup'], prefix='OnlineBackup')
ob1 = ob.drop(['OnlineBackup_No internet service'], axis =  1)
ob1 = ob1.apply(binary_dummies)
telecom = pd.concat([telecom,ob1], axis=1)

# Creating dummy variables for the variable 'DeviceProtection'.
dp = pd.get_dummies(telecom['DeviceProtection'], prefix='DeviceProtection')
dp1 = dp.drop(['DeviceProtection_No internet service'], axis =  1)
dp1 = dp1.apply(binary_dummies)
telecom = pd.concat([telecom,dp1], axis=1)

# Creating dummy variables for the variable 'TechSupport'.
ts = pd.get_dummies(telecom['TechSupport'], prefix='TechSupport')
ts1 = ts.drop(['TechSupport_No internet service'], axis =  1)
ts1 = ts1.apply(binary_dummies)
telecom = pd.concat([telecom,ts1], axis=1)

# Creating dummy variables for the variable 'StreamingTV'.
st =pd.get_dummies(telecom['StreamingTV'], prefix='StreamingTV')
st1 = st.drop(['StreamingTV_No internet service'], axis =  1)
st1 = st1.apply(binary_dummies)
telecom = pd.concat([telecom,st1], axis=1)

# Creating dummy variables for the variable 'StreamingMovies'.
sm = pd.get_dummies(telecom['StreamingMovies'], prefix='StreamingMovies')
sm1 = sm.drop(['StreamingMovies_No internet service'], axis =  1)
sm1 = sm1.apply(binary_dummies)
telecom = pd.concat([telecom,sm1], axis=1)




cm = pd.get_dummies(telecom['Contract'], prefix='Contract')
cm1 = cm.drop(['Contract_Month-to-month'], axis =  1)
cm1 = cm1.apply(binary_dummies)
telecom = pd.concat([telecom,cm1], axis=1)

pm = pd.get_dummies(telecom['PaymentMethod'], prefix='PaymentMethod')
pm1 = pm.drop(['PaymentMethod_Bank transfer (automatic)'], axis =  1)
pm1 = pm1.apply(binary_dummies)
telecom = pd.concat([telecom,pm1], axis=1)

im = pd.get_dummies(telecom['InternetService'], prefix='InternetService')
im1 = im.drop(['InternetService_No'], axis =  1)
im1 = im1.apply(binary_dummies)
telecom = pd.concat([telecom,im1], axis=1)

telecom.head()

"""#### Dropping the repeated variables"""

# We have created dummies for the below variables, so we can drop them
telecom = telecom.drop(['Contract','customerID','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
       'TechSupport', 'StreamingTV', 'StreamingMovies', 'TotalCharges','InternetService_Fiber optic'], axis = 1)

telecom.info()

"""Now you can see that you have all variables as numeric.

#### Checking for Outliers
"""

# Checking for outliers in the continuous variables
num_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen']]

# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%
num_telecom.describe(percentiles=[.25, .5, .75, .90, .95, .99])

"""From the distribution shown above, you can see that there no outliers in your data. The numbers are gradually increasing.

#### Checking for Missing Values and Inputing Them
"""

# Adding up the missing values (column-wise)
telecom.isnull().sum()

"""It means that 11/7043 = 0.001561834 i.e 0.1%, best is to remove these observations from the analysis"""

# Checking the percentage of missing values
round(100*(telecom.isnull().sum()/len(telecom.index)), 2)

# Checking percentage of missing values after removing the missing values
round(100*(telecom.isnull().sum()/len(telecom.index)), 2)

"""Now we don't have any missing values

### Step 4: Test-Train Split
"""

from sklearn.model_selection import train_test_split

# Putting feature variable to X
X = telecom.drop(['Churn'], axis=1)

X.head()

# Putting response variable to y
y = telecom['Churn']

y.head()

# Splitting the data into train and test
X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=0.7, test_size=0.3, random_state=100 , stratify= y)

"""### Step 5: Feature Scaling"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train[['tenure','MonthlyCharges']] = scaler.fit_transform(X_train[['tenure','MonthlyCharges']])

X_train.head()

"""We have almost 27% churn rate

### Step 6: Looking at Correlations
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing matplotlib and seaborn
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

# Let's see the correlation matrix
plt.figure(figsize = (20,10))        # Size of the figure
sns.heatmap(telecom.corr(),annot = True)
plt.show()

"""#### Dropping highly correlated dummy variables"""

X_test = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',
                      'StreamingTV_No','StreamingMovies_No'], axis = 1)
X_train = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',
                        'StreamingTV_No','StreamingMovies_No'], axis = 1)

"""### Step 7: Model Building
Let's start by splitting our data into a training set and a test set.

#### Running Your First Training Model
"""

import statsmodels.api as sm

# Logistic regression model
logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())
logm1.fit().summary()

"""### Step 8: Feature Selection Using RFE"""

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()

from sklearn.feature_selection import RFE

rfe = RFE(estimator= logreg, n_features_to_select=15)            # running RFE with 13 variables as output
rfe = rfe.fit(X_train, y_train)

rfe.support_

list(zip(X_train.columns, rfe.support_, rfe.ranking_))

col = X_train.columns[rfe.support_]

X_train.columns[~rfe.support_]

"""##### Assessing the model with StatsModels"""

X_train_sm = X_train[col]
logreg = LogisticRegression()

logreg.fit(X_train_sm , y_train)

# Getting the predicted values on the train set
y_train_pred = logreg.predict(X_train_sm)
y_train_pred[:10]

from sklearn import metrics

# Confusion matrix
confusion = metrics.confusion_matrix(y_train_pred, y_train )
print(confusion)

# Predicted     not_churn    churn
# Actual
# not_churn        3270      365
# churn            579       708

# Let's check the overall accuracy.
print(metrics.accuracy_score(y_train_pred, y_train))

"""#### Checking VIFs"""

# Check for the VIF values of the feature variables.
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train[col].columns
vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif          #remove InternetService_Fiber optic rebuild the model

"""All variables have a good value of VIF. So we need not drop any more variables and we can proceed with making predictions using this model only"""

TP = confusion[1,1] # true positive
TN = confusion[0,0] # true negatives
FP = confusion[0,1] # false positives
FN = confusion[1,0] # false negatives

# Let's see the sensitivity of our logistic regression model
TP / float(TP+FN)

# Let us calculate specificity
TN / float(TN+FP)

"""## Precision and Recall"""

confusion = metrics.confusion_matrix(y_train_pred, y_train )
confusion

"""##### Precision
TP / TP + FP
"""

confusion[1,1]/(confusion[0,1]+confusion[1,1])

"""##### Recall
TP / TP + FN
"""

confusion[1,1]/(confusion[1,0]+confusion[1,1])

"""Using sklearn utilities for the same"""

from sklearn.metrics import precision_score, recall_score

precision_score(y_train_pred, y_train)

recall_score(y_train_pred, y_train)

"""###Making predictions on the test set"""

X_test[['tenure','MonthlyCharges']] = scaler.transform(X_test[['tenure','MonthlyCharges']])

X_test = X_test[col]
X_test.head()

"""Making predictions on the test set"""

y_test_pred = logreg.predict(X_test)

y_test_pred[:10]

# Let's check the overall accuracy.
metrics.accuracy_score(y_test_pred, y_test)

confusion2 = metrics.confusion_matrix(y_test_pred, y_test )
confusion2

TP = confusion2[1,1] # true positive
TN = confusion2[0,0] # true negatives
FP = confusion2[0,1] # false positives
FN = confusion2[1,0] # false negatives

# Let's see the sensitivity of our logistic regression model
TP / float(TP+FN)

# Let us calculate specificity
TN / float(TN+FP)

print(classification_report(y_test, y_test_pred))

"""## Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

tree = DecisionTreeClassifier()
tree.fit(X_train_sm, y_train)

y_train_pred = tree.predict(X_train_sm)
y_test_pred = tree.predict(X_test)

print(accuracy_score(y_train, y_train_pred))
confusion_matrix(y_train, y_train_pred)

print(accuracy_score(y_test, y_test_pred))
confusion_matrix(y_test, y_test_pred)  #do hyper tuneing and check again

from sklearn.model_selection import GridSearchCV

params = {
    'max_depth': [2,3,4,5,10,20],
    'min_samples_leaf':[5 , 10, 20,50, 100],
    'criterion': ['gini' , 'entropy']
}

grid_search = GridSearchCV(estimator= tree , param_grid= params , cv = 4 ,
                           n_jobs = -1 , verbose = 1 , scoring = "accuracy")

grid_search.fit(X_train_sm , y_train)

cv_df = pd.DataFrame(grid_search.cv_results_)
cv_df.head()

cv_df.shape

cv_df.nlargest(5,'mean_test_score')

grid_search.best_score_

grid_search.best_estimator_

tree2 = grid_search.best_estimator_
tree2.fit(X_train_sm, y_train)

y_train_pred = tree2.predict(X_train_sm)
y_test_pred = tree2.predict(X_test)

print(accuracy_score(y_train, y_train_pred))
confusion_matrix(y_train, y_train_pred)

print(accuracy_score(y_test, y_test_pred))
confusion_matrix(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))

"""## SVM"""

from sklearn import svm

sv = svm.SVC(kernel='linear' , gamma = 'auto' , C = 2)
sv.fit(X_train_sm, y_train)

y_train_pred = sv.predict(X_train_sm)
y_test_pred = sv.predict(X_test)

print(accuracy_score(y_train, y_train_pred))
confusion_matrix(y_train, y_train_pred)

print(accuracy_score(y_test, y_test_pred))
confusion_matrix(y_test, y_test_pred)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_test_pred))

"""# Random Forest

"""

from sklearn.ensemble import RandomForestClassifier

forest = RandomForestClassifier(random_state= 42 , max_depth = 3 , n_estimators = 10 , oob_score= True)

forest.fit(X_train_sm , y_train)

forest.estimators_[0]

# OOB Score
# Average value of out of bag score for different tree
#the OOB score is calculated using out-of-bag samples and is a measure of the model’s performance on unseen data.
forest.oob_score_

forest = RandomForestClassifier(random_state = 42 , n_jobs= 1)

params = {
    'max_depth': [2,3,4,5,10,20],
    'min_samples_leaf':[5 , 10, 20,50, 100],
    'max_features':[5,10,15],
    'n_estimators':[10,30,50,100]
    }

grid_search = GridSearchCV(estimator = forest , param_grid = params , cv = 4 ,
                           n_jobs = -1 , verbose = 1 , scoring = "accuracy")

grid_search.fit(X_train_sm , y_train)

forest_df = pd.DataFrame(grid_search.cv_results_)
forest_df.head()

forest_df.shape

forest_df.nlargest(5,'mean_test_score')

grid_search.best_score_

grid_search.best_estimator_

forest2 = grid_search.best_estimator_
forest2.fit(X_train_sm, y_train)

y_train_pred = forest2.predict(X_train_sm)
y_test_pred = forest2.predict(X_test)

print(accuracy_score(y_train, y_train_pred))
confusion_matrix(y_train, y_train_pred)

print(accuracy_score(y_test, y_test_pred))
confusion_matrix(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))